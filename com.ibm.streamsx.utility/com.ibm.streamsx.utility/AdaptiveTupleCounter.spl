namespace com.ibm.streamsx.utility ;

use com.ibm.streamsx.utility::* ;

/**
 * The AdaptiveTupleCounter operator counts tuples that flow on the stream.
 *
 * Periodically, it displays the current throughput in the application
 * traces (at the ERROR level).  It attempts to adapt to the current
 * stream throughput, so that it only incurs the tracing cost every
 * targetInterval seconds (approximately), and most other tuples will have
 * almost no overhead caused by this operator.
 *
 * @input In              The stream from which to count tuples.
 * @param targetInterval  The desired target tracing interval (in seconds).
 *                        Traces will occur with at-most this frequency.
 *                        A value of 0 means to not trace at all (the default).
 * @param maxCheckInterval  Internally, this operator uses targetInterval and
 *                        a dynamic estimate of expected tuple throughput to
 *                        compute a check interval, measured as tuples received
 *                        since the last check, that the operator will wait before
 *                        doing anything expensive, like checking the TOD (to
 *                        determine if the given targetInterval has expired since
 *                        the most recent output trace).  However, if the tuple
 *                        throughput varies widely, in particular if it has extended
 *                        periods of time of extremely low tuple rate, and then
 *                        periodic (and relatively short) burts of traffic, much
 *                        much higher, the internally computed check interval may
 *                        become very large, if computed during a burst of high
 *                        throughput, and when the extended period of low throughput
 *                        occurs, this operator will incorrectly wait a very long time
 *                        (potentially much much longer than the targetInterval) between
 *                        TOD checks, and thus trace output.
 *                        Setting MaxCheckInterval to a non-zero value sets the maximum
 *                        number of tuples to wait between TOD checks, which can often
 *                        better handle these wildly variable throughput streams.
 *                        Setting this too low, however, can cause TOD checks too
 *                        frequently, causing excessive additional tuple latency and
 *                        hurting throughput.
 *                        The default value (0) disables this maximum, allowing the
 *                        internal check interval to vary freely.  This is optimal
 *                        for fairly steady throughput streams, with only gradual
 *                        throughput changes (over timeperiods larger than the
 *                        targetInterval).
 *
 * The AdaptiveTupleCounterTargetInterval submission-time parameter can be used
 * to control the target interval for all instances of the AdaptiveTupleCounter
 * in the application, but if a given operator invocation sets the
 * targetInterval parameter explicitly, that value will take precedence over
 * the submission time value.
 *
 * The MaxCheckInterval submission-time parameter can be used to control the
 * max check interval for all instances of the AdaptiveTupleCounter in the
 * application, but will be overridden by the direct use of the maxCheckInterval
 * parameter at the operator invocation point.  Be very careful of overriding
 * these all to the same value, since most streams will likely be fairly steady,
 * but of very different throughputs from other streams.  This may cause
 * excessive additional tuple latency added to the AdaptiveTupleCounter() on
 * some streams.
 *
 * To use the operator, simply attach an instance of this operator to the
 * desired stream.
 *
 * In an example SPL application:
 *
 * use com.ibm.streamsx.utility::*;
 * public composite Main {
 *   graph
 *
 *     // Arbitrary operators generating a stream of interest
 *     stream<int64 x> StreamUnderTest = Beacon() { ... }
 *
 *     // The AdaptiveTupleCounter
 *     () as CountStreamUnderTest = AdaptiveTupleCounter(StreamUnderTest) {}
 *
 *     // Potentially other arbitrary operators using the stream of interest
 *     () as OutputSink = FileSink(StreamUnderTest) { ... }
 * }
 *
 */
public composite AdaptiveTupleCounter(input In)
{
    param
        expression<int64> $targetInterval : (int64)getSubmissionTimeValue("AdaptiveTupleCounterTargetInterval", "0");  // Default is to disable tracing.
        expression<uint64> $maxCheckInterval : (uint64)getSubmissionTimeValue("MaxCheckInterval", "0");  // Default is to disable capping.

    graph
        () as Counter = Custom(In)
        {
          logic
            state: {
              mutable boolean first = true;
              mutable uint64 tupleCount = 0ul;
              mutable uint64 checkCount = 0ul;
              mutable int64 lasttime = 0l;
              int64 targetIntervalNs = $targetInterval * 1000000000l;
              mutable uint64 currentCheckInterval = 10ul;  // This should be way too often, but will get adjusted upwards pretty quick.
            }

            onTuple In: {
              if (first) {
                first = false;
                lasttime = getCPUCounterInNanoSeconds();
              }
              ++tupleCount;
              if(tupleCount % currentCheckInterval == 0ul) {
                  int64 thistime = getCPUCounterInNanoSeconds();
                  int64 deltaTns = thistime - lasttime;
                  ++checkCount;

                  if(targetIntervalNs > 0l) {
                      if(deltaTns > targetIntervalNs) {
                          if(deltaTns > 11l* targetIntervalNs / 8l) {
                              // It is taking way too long to get to currentCheckInterval.  Recompute currentCheckInterval (shrinking it).
                              // Overshoot by 12.5% so we should display immediately after checking, 1:1
                              currentCheckInterval = 9ul* (uint64)targetIntervalNs * tupleCount / (uint64)deltaTns / 8ul;
                              if(currentCheckInterval == 0ul) {
                                  currentCheckInterval = 1ul;
                              }
                          }

                          // Ok actually compute and trace the throughput for this tap point.
                          float64 throughput = (float64)tupleCount/((float64)deltaTns/1.0e9fl);
                          appTrc(Trace.error, "Current throughput: " + (rstring)throughput + " Tps; Checks: " + (rstring)checkCount + ", Tuples: " + (rstring)tupleCount + ", Interval: " + (rstring)((float64)deltaTns/1e9fl) + " s");

                          // Reset the counter and timestamps for next time
                          lasttime = thistime;
                          tupleCount = 0ul;
                          checkCount = 0ul;
                      } else if(deltaTns < 7l* targetIntervalNs / 8l) {
                          // Hitting currentCheckInterval way too quick.  Recompute currentCheckInterval (growing it).
                          // Overshoot by 12.5% so we should display immediately after checking, 1:1
                          currentCheckInterval = 9ul* (uint64)targetIntervalNs * tupleCount / (uint64)deltaTns / 8ul;
                          if(currentCheckInterval == 0ul) {
                              currentCheckInterval = 1ul;
                          }
                          if(($maxCheckInterval > 0ul) && (currentCheckInterval > $maxCheckInterval)) {
                              currentCheckInterval = $maxCheckInterval;
                          }
                      } else {
                          // Hitting currentCheckInterval just slightly too quick.  Leave it as it is to avoid thrashing the interval targets.
                      }
                  } else {
                      // Since we're not going to be tracing, set the currentCheckInterval to something really high to avoid wasting time in here.
                      currentCheckInterval = 0xFFFFFFFFFFFFFFFFu;
                  }
              }
            }
        }
}
